{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': ['Integrals'], 'status': ['unstarted'], 'pk': ['pk']}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "resp = requests.post(\"http://localhost:7071/api/getNodeDetails\", json={\"node_id\": \"integrals\"})\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "- test2\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "test = {\"test\":1, \"test2\":2}\n",
    "print(\"\\n- \".join(test.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 283\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# get memory\u001b[39;00m\n\u001b[1;32m    282\u001b[0m desired_visual \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a visual of a spring oscillating, moving according to Hooke\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Law. The spring should be attached to a wall on one end and a mass on the other. The mass should be displaced from its equilibrium position and then released. The mass should oscillate back and forth around the equilibrium position. The spring should be shown to stretch and compress as the mass moves. The mass should be shown to move with simple harmonic motion. The spring should be shown to obey Hooke\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Law.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 283\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are an agent whose job it is to write a python file which can be run using manim -pql scene.py ClassName to generate the animation or visual that the user requests. Don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt respond with anything except for the tool call and a 1 sentence explanation of what you did or are fixing. Don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt keep trying something that isn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt working; instead, switch to a different approach. Each time you generate a video, you will get back the stderr if there is an error generating a video or a correctness_report if the video generates but there are code changes you need to make. If the video is perfect, you will be told that no further changes need to be made.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_visual\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdesired_visual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_visual\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mprint\u001b[39m(resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# code_creation_prompt = ChatPromptTemplate.from_messages(\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# [\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m#     (\"system\", \"You are an agent whose job it is to write a python file which can be run using manim -pql scene.py ClassName to generate the animation or visual that the user requests. Don't respond with anything except for the tool call and a 1 sentence explanation of what you did or are fixing. Don't keep trying something that isn't working; instead, switch to a different approach. Each time you generate a video, you will get back the stderr if there is an error generating a video or a correctness_report if the video generates but there are code changes you need to make. If the video is perfect, you will be told that no further changes need to be made.\"),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# \"Create an animation of projectile motion with a ball being thrown off of a building towards the ground. Show the components of motion with arrows in the x and y direction from the ball that grow and shrink in proportion to how much each component of velocity is changing as the ball travels. Also, include text for the equations of motion, counters for the actual x and y components of velocity, and the height of the building in metric units.\"\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# \"Create an animation of a ball being launched off of a building and falling to the ground, following projectile motion. \"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GuideStone/lib/python3.11/site-packages/langgraph/pregel/__init__.py:579\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, output_keys, input_keys, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[1;32m    578\u001b[0m     latest: Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m latest\n",
      "File \u001b[0;32m~/anaconda3/envs/GuideStone/lib/python3.11/site-packages/langgraph/pregel/__init__.py:615\u001b[0m, in \u001b[0;36mPregel.transform\u001b[0;34m(self, input, config, output_keys, input_keys, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]]:\n\u001b[0;32m--> 615\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_stream_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GuideStone/lib/python3.11/site-packages/langchain_core/runnables/base.py:1497\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1497\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/anaconda3/envs/GuideStone/lib/python3.11/site-packages/langgraph/pregel/__init__.py:348\u001b[0m, in \u001b[0;36mPregel._transform\u001b[0;34m(self, input, run_manager, config, input_keys, output_keys, interrupt)\u001b[0m\n\u001b[1;32m    341\u001b[0m futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    342\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(proc\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m proc, \u001b[38;5;28minput\u001b[39m, config \u001b[38;5;129;01min\u001b[39;00m tasks_w_config\n\u001b[1;32m    344\u001b[0m ]\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# execute tasks, and wait for one to fail or all to finish.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# each task is independent from all other concurrent tasks\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_EXCEPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# interrupt on failure or timeout\u001b[39;00m\n\u001b[1;32m    355\u001b[0m _interrupt_or_proceed(done, inflight, step)\n",
      "File \u001b[0;32m~/anaconda3/envs/GuideStone/lib/python3.11/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    303\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 305\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m~/anaconda3/envs/GuideStone/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/GuideStone/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import operator\n",
    "from typing import Annotated, Dict, List, Optional, Sequence, Type, TypedDict\n",
    "import azure.functions as func\n",
    "from psycopg2 import pool\n",
    "from pydantic import BaseModel, Field, ValidationError, root_validator, validator, ConfigDict\n",
    "from enum import Enum\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.messages import BaseMessage, ToolMessage\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.tools.render import format_tool_to_openai_tool\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.output_parsers import OutputFixingParser, PydanticOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.tools import BaseTool\n",
    "import shutil\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from ansi2html import Ansi2HTMLConverter\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langgraph.prebuilt import ToolExecutor, ToolInvocation\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.pregel import Pregel\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from langchain.load.dump import dumps\n",
    "from langchain.load.load import loads\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__c59c7e8854d442bba00eaccff9674f47\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"GuideStone\"\n",
    "\n",
    "# REMOVE THIS BEFORE COMMITTING\n",
    "blob_service_client = BlobServiceClient.from_connection_string(\"DefaultEndpointsProtocol=https;AccountName=guidestone8419;AccountKey=jKs8aczD2qgtEVot3cs7Ud+XhxwDY0xMY6KoYKG7k0cMKiLoxR2rxK/zTV3c8mZ66ZF69ZKL9oSN+AStdShBCw==;EndpointSuffix=core.windows.net\")\n",
    "container_client = blob_service_client.get_container_client(\"manim-memory\")\n",
    "blob_client = container_client.get_blob_client(\"memory.txt\")\n",
    "downloaded_blob = blob_client.download_blob()\n",
    "memory = downloaded_blob.readall().decode(\"utf-8\")\n",
    "\n",
    "# ROTATE THIS KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"10388fa13cbd4ca0aa189687aa4b3af1\"\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = \"https://gpt-4-beta-canada.openai.azure.com/\"\n",
    "\n",
    "gpt_4_llm = AzureChatOpenAI(deployment_name=\"gpt-4-turbo\", api_version=\"2023-07-01-preview\", model_name=\"gpt-4-1106-preview\", temperature=0, max_retries=10)\n",
    "\n",
    "class CodeGenerateSchema(BaseModel):\n",
    "    manim_code: str = Field(description=\"Manim code that generates the visuals for the scene. Treat this field as the equivalent to a .py file; it must be NOTHING BUT Python code and be able to be executed with manim -pql scene.py <class_name> AS-IS.\")\n",
    "    class_name: str = Field(description=\"The Manim scene class to use when running the manim -pql scene.py <class_name> command to render the video\")\n",
    "    desired_visual: str = Field(description=\"The exact input the user gave you describing the visual they want you to create\")\n",
    "\n",
    "    @root_validator\n",
    "    def is_valid_code(cls, v):\n",
    "        try:\n",
    "            parsed_module = ast.parse(v['manim_code'])\n",
    "            class_names = [node.name for node in ast.walk(parsed_module) if isinstance(node, ast.ClassDef)]\n",
    "            if not any([v['class_name'] in name for name in class_names]):\n",
    "                raise ValueError(\"Target render class not found in code!\")\n",
    "        except SyntaxError:\n",
    "            raise ValueError(\"Code is not valid Python\")\n",
    "        return v\n",
    "    \n",
    "class CodeIssue(BaseModel):\n",
    "    issue: str = Field(description=\"\"\"A description of what issue with the animation this code will cause. Only report issues that fall into the below categories. Don't report the category itself, just what the actual issue is in the animation (e.g. the end of the pendulum moves at a different rate from the spring, causing the two to separate)\n",
    "                       - issues that cause the animation to be choppy\n",
    "                       - issues that cause elements to move out of the video and be cut off or not visible\n",
    "                       - issues that cause elements to incorrectly overlap\n",
    "                       - issues that cause animations to render off-center in the video\n",
    "                       - issues that cause elements that should move as 1 component to move at different speeds or in different directions\n",
    "                       - instances where movement that should be determined by physical equations is not determined by those equations (e.g., a pendulum that doesn't move according to the pendulum equation)\n",
    "                       - issues that cause latex code will render as plain text with markup visible\n",
    "                       - issues that cause elements to render larger or smaller than they should be for comfortable viewing\n",
    "                       - issues where an animation is too long or short to voice over (e.g., a pendulum swinging for an entire minute or only once) UNLESS THE USER SPECIFICALLY REQUESTS IT\"\"\")\n",
    "    code: str = Field(description=\"The code that causes the issue\")\n",
    "    improvement: str = Field(description=\"Code to replace the code field that will fix the issue. If the issue is not fixable, DON'T REPORT THE ISSUE AT ALL\")\n",
    "\n",
    "class CodeCorrectnessReport(BaseModel):\n",
    "    issues: List[CodeIssue] = Field(description=\"A list of issues with the code that will cause the animation to differ from the user's desired visual. DO NOT include any issues in this list that do not match the categories in the issue field of the CodeIssue model. If there are no such issues, this field should be an empty list\")\n",
    "    \n",
    "code_parser = PydanticOutputParser(pydantic_object=CodeCorrectnessReport)\n",
    "code_fixing_parser = OutputFixingParser.from_llm(parser=code_parser, llm=gpt_4_llm)\n",
    "\n",
    "class VideoGenerate(BaseTool):\n",
    "    name = \"RenderVideo\"\n",
    "    description = \"Attempts to render the provided code into a video file and provides the stdout and stderr of the render process\"\n",
    "    args_schema: Type[BaseModel] = CodeGenerateSchema\n",
    "    conv = Ansi2HTMLConverter()\n",
    "\n",
    "    model_config = ConfigDict(from_attributes=True)\n",
    "\n",
    "    def _run(self, manim_code: str, class_name: str, desired_visual: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"generate a video synchronously.\"\"\"\n",
    "\n",
    "        # get rid of old generation stuff\n",
    "        if os.path.isfile(\"scene.py\"):\n",
    "            os.remove(\"scene.py\")\n",
    "        if os.path.isdir(\"media\"):\n",
    "            shutil.rmtree(\"media\")\n",
    "\n",
    "        # write the code to a file\n",
    "        with open(\"scene.py\", \"w\") as scene:\n",
    "            scene.write(manim_code)\n",
    "\n",
    "        stdout, stderr = subprocess.Popen(f\"manim -pql scene.py {class_name}\", stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=True).communicate()\n",
    "        stdout_decoded = stdout.decode('utf-8')\n",
    "        stderr_decoded = stderr.decode('utf-8')\n",
    "\n",
    "        stdout_html = self.conv.convert(stdout_decoded)\n",
    "        stderr_html = self.conv.convert(stderr_decoded)\n",
    "\n",
    "        resp = {}\n",
    "\n",
    "        # video rendered successfully; check for correctness\n",
    "        if \"File</span> ready at\" in stdout_html:\n",
    "            # file rendered successfully\n",
    "\n",
    "            # check code\n",
    "            code_checking_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", \"You are an agent whose job it is to grade how well a user's manim code generates their desired visual. The user will provide you with your code, and then the visual they are trying to generate. Ignore the educational context of the video entirely. You are only focusing on how accurate the video is to the user's desired visual. Return your answer in the following format: {format_instructions}\"),\n",
    "                    (\"user\", '{manim_code}\\n\\nWhen this manim code is rendered the user wants the following to happen: \"{desired_visual}\"\\nDoes this code achieve this? Point out any specific code flaws that will cause the resulting animation to differ from that the user requested. DO NOT report any issue with the educational impact of the animation. For example if damping is not accounted for and the desired visual doesn\\'t include damping, DO NOT say that damping should be added. If the video accurately creates the animation requested, tell the user that no further modifications are required.'),\n",
    "                ]\n",
    "            )\n",
    "            code_checking_chain = (\n",
    "                {\n",
    "                    \"format_instructions\": itemgetter(\"format_instructions\"),\n",
    "                    \"manim_code\": itemgetter(\"manim_code\"),\n",
    "                    \"desired_visual\": itemgetter(\"desired_visual\"),\n",
    "                }\n",
    "                | code_checking_prompt\n",
    "                | gpt_4_llm\n",
    "                | code_fixing_parser\n",
    "            )\n",
    "\n",
    "            code_correctness_output = code_checking_chain.invoke({\n",
    "                \"format_instructions\": code_fixing_parser.get_format_instructions(),\n",
    "                \"manim_code\": manim_code,\n",
    "                \"desired_visual\": desired_visual\n",
    "            })\n",
    "\n",
    "            if code_correctness_output.issues == []:\n",
    "                resp[\"correctness_report\"] = \"The code accurately generates the desired visual. No further action is needed\"\n",
    "            else:\n",
    "                resp[\"correctness_report\"] = code_correctness_output.dict()\n",
    "\n",
    "            # copy file to saved spot\n",
    "            html_obliterator = re.compile('<.*?>') \n",
    "            stdout_plain = re.sub(html_obliterator, '', stdout_html)\n",
    "            stdout_plain = stdout_plain.replace(\"\\n\", \"\")\n",
    "            stdout_plain = \"\".join(stdout_plain.split())\n",
    "            url = re.compile(r\"Filereadyat'([^']+)'\").search(stdout_plain).group(1)\n",
    "            shutil.copy\n",
    "        else:\n",
    "            resp[\"stdout\"] = stdout_html\n",
    "            resp[\"stderr\"] = stderr_html\n",
    "\n",
    "\n",
    "        # if \"See log output above or the log file:\\n\" in console_response[\"stderr\"]:\n",
    "        #     try:\n",
    "        #         log_url = re.compile(r\"\\w+\\/\\w+\\/[\\w\\d]+\\.log\").search(console_response[\"stderr\"]).group(0)\n",
    "        #         with open(log_url, \"r\") as log:\n",
    "        #             log_contents = log.read()\n",
    "\n",
    "        #         console_response[\"latex_log\"] = log_contents\n",
    "        #     except:\n",
    "        #         print(\"couldn't get latex log\")\n",
    "\n",
    "        # See log output above or the log file:\\nmedia/Tex/9587f5ca887a1ae0.log\n",
    "\n",
    "        return json.dumps(resp)\n",
    "        \n",
    "    def _arun(self, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Generate a video segment asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"TextGenerate does not support async\")\n",
    "    \n",
    "class CodeCreateState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    memory: str\n",
    "    desired_visual: str\n",
    "\n",
    "class ThingLearned(BaseModel):\n",
    "    goal: str = Field(description=\"What you were trying to do with this specific piece of code (e.g. make a spring and weight visually move together, or represent a spring visually). DO NOT just state the animation goal given by the user here; this field is for more specific goals\")\n",
    "    original_code: str = Field(description=\"The code you initially wrote to try to achieve the goal\")\n",
    "    issue: str = Field(description=\"The issue you encountered with that code\")\n",
    "    final_code: str = Field(description=\"The code that fixed the issue\")\n",
    "    explanation: str = Field(description=\"A 1 sentence explanation of why the final code fixed the issue\")\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    things_learned: List[ThingLearned] = Field(description=\"A list of things you learned about writing Manim code from the process of writing the user's code. Be sure to include all the minsconceptions you had so that you can remeber this information and avoid them in the future. DO NOT include issues that you didn't solve.\")\n",
    "    \n",
    "reflection_parser = PydanticOutputParser(pydantic_object=Reflection)\n",
    "reflection_fixing_parser = OutputFixingParser.from_llm(parser=reflection_parser, llm=gpt_4_llm)\n",
    "\n",
    "# INCLUDE PROMPTING STYLE IN TEACHING EFFECTIVENESS REPORT. LACK OF ATTENTION CAN BE BECAUSE OF SHITTY VISUALS\n",
    "tools = [VideoGenerate()]\n",
    "tool_executor = ToolExecutor(tools)\n",
    "tools_oai = [format_tool_to_openai_tool(tool) for tool in tools]\n",
    "gpt4_tools = gpt_4_llm.bind(tools=tools_oai)\n",
    "\n",
    "def should_continue(state: CodeCreateState) -> str:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    if \"tool_calls\" not in last_message.additional_kwargs:\n",
    "        reflection_prompts = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", \"You are an agent whose job it is to reflect on the steps taken by a user to create an animation of a desired visual and reflect on what they learned. The user has amnesia, so you need to do this so you can help them remember and not run into the same issues again in the future. Return your answer in the following format: {format_instructions}\"),\n",
    "                (\"user\", \"I just took these steps to make this animation: \\\"{desired_visual}\\\"\\n\\n{steps}\"),\n",
    "            ]\n",
    "        )\n",
    "        reflection_chain = (\n",
    "            {\n",
    "                \"format_instructions\": itemgetter(\"format_instructions\"),\n",
    "                \"desired_visual\": itemgetter(\"desired_visual\"),\n",
    "                \"steps\": itemgetter(\"steps\"),\n",
    "            }\n",
    "            | reflection_prompts\n",
    "            | gpt_4_llm\n",
    "            | reflection_fixing_parser\n",
    "        )\n",
    "        reflection_result = reflection_chain.invoke({\n",
    "            \"format_instructions\": reflection_fixing_parser.get_format_instructions(),\n",
    "            \"desired_visual\": state[\"desired_visual\"],\n",
    "            \"steps\": dumps(state[\"messages\"])\n",
    "        })\n",
    "\n",
    "        existing_memory: Reflection = loads(state[\"memory\"])\n",
    "        existing_memory.things_learned.extend(reflection_result.things_learned)\n",
    "\n",
    "        updated_memory_str = dumps(existing_memory)\n",
    "\n",
    "        # write to blob storage\n",
    "        blob_client.upload_blob(updated_memory_str, overwrite=True)\n",
    "\n",
    "\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "    \n",
    "def call_model(state: CodeCreateState) -> Dict[str, list[BaseMessage]]:\n",
    "    messages = state['messages']\n",
    "    response = gpt4_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_tool(state: CodeCreateState) -> Dict[str, list[BaseMessage]]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    calls = [ x for x in last_message.additional_kwargs[\"tool_calls\"] ]\n",
    "    tool_messages = []\n",
    "\n",
    "    for call in calls:\n",
    "        call_type = call[\"type\"]\n",
    "        call_id = call[\"id\"]\n",
    "\n",
    "        action = ToolInvocation(\n",
    "            tool=call[call_type][\"name\"],\n",
    "            tool_input=json.loads(call[call_type][\"arguments\"]),\n",
    "        )\n",
    "\n",
    "        response = tool_executor.invoke(action)\n",
    "\n",
    "        tool_message = ToolMessage(content=str(response), tool_call_id=call_id)\n",
    "        tool_messages.append(tool_message)\n",
    "\n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "workflow = StateGraph(CodeCreateState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "app = workflow.compile()\n",
    "\n",
    "# get memory\n",
    "desired_visual = \"Create a visual of a spring oscillating, moving according to Hooke's Law. The spring should be attached to a wall on one end and a mass on the other. The mass should be displaced from its equilibrium position and then released. The mass should oscillate back and forth around the equilibrium position. The spring should be shown to stretch and compress as the mass moves. The mass should be shown to move with simple harmonic motion. The spring should be shown to obey Hooke's Law.\"\n",
    "resp = app.invoke({\n",
    "    \"messages\": [\n",
    "        (\"system\", \"You are an agent whose job it is to write a python file which can be run using manim -pql scene.py ClassName to generate the animation or visual that the user requests. Don't respond with anything except for the tool call and a 1 sentence explanation of what you did or are fixing. Don't keep trying something that isn't working; instead, switch to a different approach. Each time you generate a video, you will get back the stderr if there is an error generating a video or a correctness_report if the video generates but there are code changes you need to make. If the video is perfect, you will be told that no further changes need to be made.\"),\n",
    "        (\"user\", desired_visual),\n",
    "    ],\n",
    "    \"memory\": memory,\n",
    "    \"desired_visual\": desired_visual\n",
    "})\n",
    "\n",
    "print(resp['messages'][-1].content)\n",
    "\n",
    "# code_creation_prompt = ChatPromptTemplate.from_messages(\n",
    "    # [\n",
    "    #     (\"system\", \"You are an agent whose job it is to write a python file which can be run using manim -pql scene.py ClassName to generate the animation or visual that the user requests. Don't respond with anything except for the tool call and a 1 sentence explanation of what you did or are fixing. Don't keep trying something that isn't working; instead, switch to a different approach. Each time you generate a video, you will get back the stderr if there is an error generating a video or a correctness_report if the video generates but there are code changes you need to make. If the video is perfect, you will be told that no further changes need to be made.\"),\n",
    "    #     (\"user\", \"{desired_animation}\"),\n",
    "    #     MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    # ]\n",
    "# )\n",
    "# code_creation_chain = (\n",
    "#     {\n",
    "#         \"desired_animation\": itemgetter(\"desired_animation\"),\n",
    "#         \"agent_scratchpad\": itemgetter(\"intermediate_steps\") | RunnableLambda(format_to_openai_tool_messages),\n",
    "#     }\n",
    "#     | code_creation_prompt\n",
    "#     | gpt_4_llm.bind(tools=tools_oai)\n",
    "#     | OpenAIToolsAgentOutputParser()\n",
    "# ).with_retry()\n",
    "\n",
    "# agent = AgentExecutor(agent=code_creation_chain, tools=tools, verbose=True)\n",
    "\n",
    "# # 1. get basic video working (animations, equations, text)\n",
    "# # 2. incorporate visuals\n",
    "# # 3. incorporate plugins\n",
    "\n",
    "# # Create a visual of a spring oscillating, moving according to Hooke's Law. The spring should be attached to a wall on one end and a mass on the other. The mass should be displaced from its equilibrium position and then released. The mass should oscillate back and forth around the equilibrium position. The spring should be shown to stretch and compress as the mass moves. The mass should be shown to move with simple harmonic motion. The spring should be shown to obey Hooke's Law. The mass should be shown to obey Newton's Second Law. The mass should be shown to have kinetic energy and potential energy. The spring should be shown to have elastic potential energy. The mass should be shown to have maximum kinetic energy at the equilibrium position and maximum potential energy at the maximum displacement from the equilibrium position. The spring should be shown to have maximum elastic potential energy at the maximum displacement from the equilibrium position and maximum kinetic energy at the equilibrium position.\n",
    "# # Create an animation of 2-d Hooke's Law with a square with arrows pointing up and to the right for the x and y components of the force. Then fade in the equation for the x component, epsilon_x=sigma_x/E-v*sigma_y/E, and the equation for the y component, epsilon_y=sigma_y/E-v*sigma_x/E, one after the other\n",
    "\n",
    "# code_output = agent.invoke({\n",
    "#     \"desired_animation\": \"Create a visual of a spring oscillating, moving according to Hooke's Law. The spring should be attached to a wall on one end and a mass on the other. The mass should be displaced from its equilibrium position and then released. The mass should oscillate back and forth around the equilibrium position. The spring should be shown to stretch and compress as the mass moves. The mass should be shown to move with simple harmonic motion. The spring should be shown to obey Hooke's Law.\",\n",
    "# })\n",
    "\n",
    "# \"Create an animation of projectile motion with a ball being thrown off of a building towards the ground. Show the components of motion with arrows in the x and y direction from the ball that grow and shrink in proportion to how much each component of velocity is changing as the ball travels. Also, include text for the equations of motion, counters for the actual x and y components of velocity, and the height of the building in metric units.\"\n",
    "# \"Create an animation of a ball being launched off of a building and falling to the ground, following projectile motion. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/owenburns/workareas/guidestone-functions/media/videos/scenecopy/480p15/OscillatingSpring.mp4\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from ansi2html import Ansi2HTMLConverter\n",
    "import re\n",
    "\n",
    "# stdout, stderr = subprocess.Popen(f\"manim -pql scene\\ copy.py OscillatingSpring\", stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=True).communicate()\n",
    "# stdout_decoded = stdout.decode('utf-8')\n",
    "# stderr_decoded = stderr.decode('utf-8')\n",
    "# conv = Ansi2HTMLConverter()\n",
    "# stdout_html = conv.convert(stdout_decoded)\n",
    "# stderr_html = conv.convert(stderr_decoded)\n",
    "html_obliterator = re.compile('<.*?>') \n",
    "stdout_plain = re.sub(html_obliterator, '', stdout_html)\n",
    "stdout_plain = stdout_plain.replace(\"\\n\", \"\")\n",
    "stdout_plain = \"\".join(stdout_plain.split())\n",
    "url_finder = re.compile(r\"Filereadyat'([^']+)'\").search(stdout_plain).group(1)\n",
    "print(url_finder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GuideStone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
